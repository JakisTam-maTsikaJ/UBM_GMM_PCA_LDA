{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from IPython.display import clear_output\n",
    "import librosa\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ścieżka do pliku tekstowego, w którym znajdują się informacje o mówcach\n",
    "file_path = 'C:/Users/zbugo/Desktop/praktyki_zadania/8/train-clean-100/LibriSpeech/SPEAKERS.TXT'\n",
    "\n",
    "#Tworzę ramkę danych, w której znajdują się informacje o płci danego mówcy\n",
    "df = pd.read_csv(file_path, sep='|', comment=';', usecols=[0, 1], \n",
    "                 names=[\"ID\", \"SEX\"])\n",
    "\n",
    "\n",
    "\n",
    "#Ścieżka do folderu, w którym znajdują się katalogi z nagraniami osób\n",
    "file_path = 'C:/Users/zbugo/Desktop/praktyki_zadania/8/train-clean-100/LibriSpeech/train-clean-100/'\n",
    "\n",
    "#Wyciągam wszystkie nazwy podfolderów z powyższej ścieżki (są to ID nagranych osób)\n",
    "subfolders = [f.name for f in os.scandir(file_path) if f.is_dir()]\n",
    "\n",
    "#Sortuję ID nagranych osób (najpierw muszę zamienić ID na liczbę)\n",
    "subfolders = sorted([int(item) for item in subfolders])\n",
    "subfolders = np.array(subfolders)\n",
    "\n",
    "df = df.loc[np.isin(np.array(df['ID']), subfolders)]\n",
    "\n",
    "#Tworzę oddzielne ramki dla kobiet i mężczyzn\n",
    "df_woman = df[df['SEX'] == ' F '].reset_index(drop=True)\n",
    "df_man = df[df['SEX'] == ' M '].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8975\n"
     ]
    }
   ],
   "source": [
    "#wyciągam foldery spekerów \n",
    "folders_path = \"C:/Users/zbugo/Desktop/praktyki_zadania/8/train-clean-100/LibriSpeech/train-clean-100\"\n",
    "subfolders = [f.name for f in os.scandir(folders_path) if f.is_dir()]\n",
    "subfolders = sorted([int(item) for item in subfolders])\n",
    "subfolders = [str(item) for item in subfolders]\n",
    "#np. C:/Users/zbugo/Desktop/praktyki_zadania/8/train-clean-100/LibriSpeech/train-clean-100/19\n",
    "#gdzie 19 to ID\n",
    "\n",
    "#tworzę łączę C:/Users/zbugo/Desktop/praktyki_zadania/8/train-clean-100/LibriSpeech/train-clean-100 z ID aby uzyskać efekt jak pokazałem wyżej\n",
    "#np. C:/Users/zbugo/Desktop/praktyki_zadania/8/train-clean-100/LibriSpeech/train-clean-100/19\n",
    "paths_with_ID = [folders_path + '/'+ subfolder for subfolder in subfolders]\n",
    "\n",
    "#tworzę puste ramki aby przechowywać ID osoby i łączny czas nagrania\n",
    "data_frame_for_duration_woman = pd.DataFrame(columns=['ID', 'duration'])\n",
    "data_frame_for_duration_man = pd.DataFrame(columns=['ID', 'duration'])\n",
    "\n",
    "#w pętli liczę łączny czas nagrań wszystkich osób \n",
    "for path_with_ID in paths_with_ID:\n",
    "\n",
    "    paths_inside_ID = [f.name for f in os.scandir(path_with_ID) if f.is_dir()]\n",
    "\n",
    "    full_paths_to_files = [path_with_ID + '/' + path_inside_ID for path_inside_ID in paths_inside_ID]\n",
    "\n",
    "    all_files_for_ID = []\n",
    "    for full_path_to_files in full_paths_to_files:\n",
    "        files = [f.name for f in os.scandir(full_path_to_files) if f.is_file() and f.name.endswith('.flac')]\n",
    "        files = [full_path_to_files + '/' + file for file in files]\n",
    "        all_files_for_ID = all_files_for_ID + files\n",
    "\n",
    "\n",
    "    duration_in_seconds = 0\n",
    "    for file_for_ID in all_files_for_ID:\n",
    "        with sf.SoundFile(file_for_ID) as f:\n",
    "            frames = len(f)  \n",
    "            sample_rate = f.samplerate  \n",
    "        duration = frames / sample_rate\n",
    "        duration_in_seconds = duration_in_seconds + duration\n",
    "    \n",
    "\n",
    "    ID = path_with_ID.split('/')[-1]\n",
    "    new_record = [ID, duration_in_seconds]\n",
    "    \n",
    "    if np.isin(ID, df_woman['ID']):\n",
    "        data_frame_for_duration_woman.loc[len(data_frame_for_duration_woman)] = new_record\n",
    "    else:\n",
    "        data_frame_for_duration_man.loc[len(data_frame_for_duration_man)] = new_record\n",
    "\n",
    "    print(ID)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "#sortuję dane tak aby łączny czas nagrania był malejący\n",
    "data_frame_for_duration_woman = data_frame_for_duration_woman.sort_values(by='duration', ascending=False)\n",
    "data_frame_for_duration_man = data_frame_for_duration_man.sort_values(by='duration', ascending=False)\n",
    "\n",
    "#wybieram 50 mężczyzn i 50 kobiet których łączny czas nagrań był najdłuższy\n",
    "top_50_man = data_frame_for_duration_man.head(50)\n",
    "top_50_woman = data_frame_for_duration_woman.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_path = \"C:/Users/zbugo/Desktop/praktyki_zadania/8/train-clean-100/LibriSpeech/train-clean-100\"\n",
    "\n",
    "#tworzę ścieżki do osób których łączny czas nagrań jest najdłuższy\n",
    "top_50_man_paths = [folders_path + '/' + ID for ID in top_50_man['ID']]\n",
    "top_50_woman_paths = [folders_path + '/' + ID for ID in top_50_woman['ID']]\n",
    "\n",
    "top_50_man_and_woman = top_50_man_paths + top_50_woman_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "audio_owner = []\n",
    "\n",
    "for i in range(0,100):\n",
    "\n",
    "    ID = top_50_man_and_woman[i].split('/')[-1]\n",
    "    \n",
    "    #teraz jestem w folderze z ID np. C:/Users/zbugo/Desktop/praktyki_zadania/8/train-clean-100/LibriSpeech/train-clean-100/19\n",
    "    paths_inside_ID = [f.name for f in os.scandir(top_50_man_and_woman[i]) if f.is_dir()]\n",
    "\n",
    "    #teraz jestem w folderze z danej osoby np. C:/Users/zbugo/Desktop/praktyki_zadania/8/train-clean-100/LibriSpeech/train-clean-100/19/198\n",
    "    full_paths_to_files = [top_50_man_and_woman[i] + '/' + path_inside_ID for path_inside_ID in paths_inside_ID]\n",
    "        \n",
    "    \n",
    "\n",
    "    #w pętli wyciągam wszystkie ścieżki do nagrań danej osoby czyli np.\n",
    "    #C:/Users/zbugo/Desktop/praktyki_zadania/8/train-clean-100/LibriSpeech/train-clean-100/19/198/19-198-0000.flac\n",
    "    #w all_files_for_ID przechowuje ścieżki do wszysktich plików danej osoby\n",
    "    for full_path_to_files in full_paths_to_files:\n",
    "        files = [f.name for f in os.scandir(full_path_to_files) if f.is_file() and f.name.endswith('.flac')]\n",
    "        files = [full_path_to_files + '/' + file for file in files]\n",
    "        audio_owner.extend([ID] * len(files))\n",
    "        all_files = all_files + files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zbugo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator GaussianMixture from version 1.2.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('C:/Users/zbugo/Desktop/praktyki_zadania/12/gmm.pkl', 'rb') as file:\n",
    "    UBM = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Liczba współczynników, które otrzymamy po przeprowadzeniu MFCC — ta ilość współczynników powstaje w wyniku DCT (dyskretnej transformacji kosinusowej)\n",
    "quantity_of_mel_coef = 13\n",
    "#Liczba filtrów melowych — ilość 'czapek', które zostaną nałożone na sygnał. Dla każdego z nich będzie sumowana energia\n",
    "quantity_of_mel_filters = 26\n",
    "#próbkowanie\n",
    "sr = 16000 \n",
    "\n",
    "mean_predict_proba_df = pd.DataFrame()\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "#w pętli liczę embeddingi nagrań trenujących model UBM\n",
    "for file in all_files:\n",
    "    signal, sr = librosa.load(file, sr = sr)\n",
    "    mfcc_signal = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=quantity_of_mel_coef, n_mels = quantity_of_mel_filters).T\n",
    "    mfcc_signal = pd.DataFrame(mfcc_signal)\n",
    "    embedding = pd.DataFrame(pd.DataFrame(UBM.predict_proba(mfcc_signal)).mean()).T\n",
    "    mean_predict_proba_df = pd.concat([mean_predict_proba_df, embedding], ignore_index=True)\n",
    "\n",
    "    iteration = iteration + 1\n",
    "\n",
    "    print(iteration/len(all_files))\n",
    "    clear_output(wait=True)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nadaję indeksu, w taki sposób aby było wiadamo kto jest właścicielem nagrania, a właścieiwe embeddingu\n",
    "mean_predict_proba_df.index = audio_owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_predict_proba_df.to_pickle('mean_predict_proba_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
